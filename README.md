# ⚡ High-Performance Multi-LLM Chatbot: Streamlit UI with Groq for Ultra-Fast Inferencing

This project is an enterprise-grade, modular chatbot application powered by **Streamlit** and **LangChain**, supporting **OpenAI**, **Groq**, and **Ollama** backends. It enables **ultra-fast inferencing** using **Groq’s Gemma LLM**, alongside flexible integration with other models.

---

## 🚀 Key Features

- 🧠 **Supports OpenAI, Groq, and Ollama models**
- ⚡ **Groq integration for blazing-fast inference**
- 🖼️ Clean, interactive **Streamlit-based user interface**
- 🧩 Plug-and-play LLM backend switching
- 🔧 Real-time control over **temperature** and **max tokens**
- 📜 **Session-based chat history** and memory management
- 🔐 Secure API key handling with `.env`

---

## 🧱 Built With

- [Streamlit](https://streamlit.io/)
- [LangChain](https://www.langchain.com/)
- [Groq API (Gemma2-9b-it)](https://console.groq.com/)
- [OpenAI API](https://platform.openai.com/)
- [Ollama](https://ollama.com/) — for local lightweight models
- [Python-dotenv](https://pypi.org/project/python-dotenv/)

---

## 🛠️ Setup Instructions

1. **Clone the Repository**

```bash
git clone https://github.com/yourusername/high-performance-multi-llm-chatbot.git
cd high-performance-multi-llm-chatbot
