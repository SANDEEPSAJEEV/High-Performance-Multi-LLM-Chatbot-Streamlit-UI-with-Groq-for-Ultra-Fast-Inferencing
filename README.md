# âš¡ High-Performance Multi-LLM Chatbot: Streamlit UI with Groq for Ultra-Fast Inferencing

This project is an enterprise-grade, modular chatbot application powered by **Streamlit** and **LangChain**, supporting **OpenAI**, **Groq**, and **Ollama** backends. It enables **ultra-fast inferencing** using **Groqâ€™s Gemma LLM**, alongside flexible integration with other models.

---

## ğŸš€ Key Features

- ğŸ§  **Supports OpenAI, Groq, and Ollama models**
- âš¡ **Groq integration for blazing-fast inference**
- ğŸ–¼ï¸ Clean, interactive **Streamlit-based user interface**
- ğŸ§© Plug-and-play LLM backend switching
- ğŸ”§ Real-time control over **temperature** and **max tokens**
- ğŸ“œ **Session-based chat history** and memory management
- ğŸ” Secure API key handling with `.env`

---

## ğŸ§± Built With

- [Streamlit](https://streamlit.io/)
- [LangChain](https://www.langchain.com/)
- [Groq API (Gemma2-9b-it)](https://console.groq.com/)
- [OpenAI API](https://platform.openai.com/)
- [Ollama](https://ollama.com/) â€” for local lightweight models
- [Python-dotenv](https://pypi.org/project/python-dotenv/)

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the Repository**

```bash
git clone https://github.com/yourusername/high-performance-multi-llm-chatbot.git
cd high-performance-multi-llm-chatbot
